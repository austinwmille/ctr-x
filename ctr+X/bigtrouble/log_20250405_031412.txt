2025-04-05 03:14:12,139 - INFO - 
==================================================

2025-04-05 03:14:12,139 - INFO - 
nips' brainrot generator

2025-04-05 03:14:14,152 - INFO - 
===============================================================================

2025-04-05 03:14:26,950 - INFO - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]
2025-04-05 03:14:26,950 - INFO - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
2025-04-05 03:14:30,176 - INFO - 
===============================================================================

2025-04-05 03:14:30,176 - INFO - 
packages are ready

2025-04-05 03:14:32,191 - INFO - setting up folders...

2025-04-05 03:14:33,201 - INFO - 'temp' directory named 'imthetrashman'

2025-04-05 03:14:34,210 - INFO - folder to store un-processed videos: 'C:\Users\austi\Desktop\ctrx\processmesempai'

2025-04-05 03:14:34,210 - INFO - processed clips will be stored in 'C:\Users\austi\Desktop\ctrx\ctrs'

2025-04-05 03:14:34,210 - INFO - after processing, og video files will move from 'C:\Users\austi\Desktop\ctrx\processmesempai' to 'C:\Users\austi\Desktop\ctrx\done'


2025-04-05 03:14:36,224 - INFO - Setting parameters for whisperX. For more details, visit: https://github.com/m-bain/whisperX
2025-04-05 03:14:38,231 - INFO - whisper_arch = 'medium'
device = 'cpu' 
compute_type = 'int8'
language = 'en'

2025-04-05 03:14:45,097 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\Users\austi\.cache\torch\whisperx-vad-segmentation.bin`
2025-04-05 03:14:45,122 - INFO - next section loads pyannote auth token

2025-04-05 03:14:48,138 - INFO - 
===================================================================

2025-04-05 03:14:50,232 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\Users\austi\.cache\torch\pyannote\models--pyannote--segmentation\snapshots\c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b\pytorch_model.bin`
2025-04-05 03:14:50,307 - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-05 03:14:50,456 - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-05 03:14:50,822 - INFO - Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-05 03:14:50,932 - INFO - Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-05 03:14:51,072 - INFO - Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-05 03:14:51,212 - INFO - Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-05 03:14:51,382 - INFO - Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder
2025-04-05 03:14:51,567 - INFO - 
===================================================================

2025-04-05 03:14:51,567 - INFO - setup completed.

2025-04-05 03:14:52,572 - INFO - we will now begin processing 1 videos
2025-04-05 03:14:53,572 - INFO - The time required varies hugely on your computing hardware and selected parameters.

2025-04-05 03:14:53,572 - INFO - Godspeed

2025-04-05 03:14:53,572 - INFO - 
===============================

C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\core\io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:43: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  backend = torchaudio.get_audio_backend()
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0
  from speechbrain.pretrained import (
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:53: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend(backend)
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\tasks\segmentation\mixins.py:37: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.
  from torchaudio.backend.common import AudioMetaData
[nltk_data] Downloading package punkt to
[nltk_data]     C:\Users\austi\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt is already up-to-date!
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\speechbrain\utils\fetching.py:151: UserWarning: Using SYMLINK strategy on Windows for fetching potentially requires elevated privileges and is not recommended. See `LocalStrategy` documentation.
  warnings.warn(
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\speechbrain\utils\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.
  warnings.warn(
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\austi\AppData\Local\Programs\Python\Python39\lib\logging\__init__.py", line 1086, in emit
    stream.write(msg + self.terminator)
  File "C:\Users\austi\AppData\Local\Programs\Python\Python39\lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\uff5c' in position 129: character maps to <undefined>
Call stack:
  File "C:\Users\austi\Desktop\ctrx\clipmev2.py", line 193, in <module>
  File "C:\Users\austi\Desktop\ctrx\clipmev2.py", line 58, in new_logging_info
    original_logging_info(*args, **kwargs)
Unable to print the message and arguments - possible formatting error.
Use the traceback above to help find the error.
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cpu. Bad things might happen unless you revert torch to 1.x.
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cpu. Bad things might happen unless you revert torch to 1.x.
Traceback (most recent call last):
  File "C:\Users\austi\Desktop\ctrx\clipmev2.py", line 197, in <module>
    extracted_audio_file_path=extracted_audio_path,
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\clipsai\media\audio_file.py", line 133, in extract_audio
    self.assert_exists()
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\clipsai\filesys\object.py", line 157, in assert_exists
    msg = self.check_exists()
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\clipsai\media\audiovideo_file.py", line 71, in check_exists
    error = temporal_media_file.check_exists()
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\clipsai\media\temporal_media_file.py", line 65, in check_exists
    msg = super().check_exists()
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\clipsai\media\media_file.py", line 79, in check_exists
    if file.get_mime_primary_type() not in valid_media_file_types:
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\clipsai\filesys\file.py", line 232, in get_mime_primary_type
    file_type, _ = self.get_mime_type().split("/")
ValueError: not enough values to unpack (expected 2, got 1)
