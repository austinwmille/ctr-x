2025-04-07 22:20:36,947 - INFO - 
==================================================

2025-04-07 22:20:36,947 - INFO - 
nips' brainrot generator

2025-04-07 22:20:36,949 - INFO - 
===============================================================================

2025-04-07 22:20:53,841 - INFO - Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]
2025-04-07 22:20:53,841 - INFO - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
2025-04-07 22:20:55,911 - INFO - 
===============================================================================

2025-04-07 22:20:55,911 - INFO - packages loaded

2025-04-07 22:20:57,923 - INFO - setting up folders...

2025-04-07 22:20:58,941 - INFO - 'temp' directory named 'imthetrashman'

2025-04-07 22:20:59,957 - INFO - folder to store un-processed videos: 'C:\Users\austi\Desktop\ctrx\processmesempai'

2025-04-07 22:20:59,957 - INFO - processed clips will be stored in 'C:\Users\austi\Desktop\ctrx\ctrs'

2025-04-07 22:20:59,957 - INFO - after processing, og video files will move from 'C:\Users\austi\Desktop\ctrx\processmesempai' to 'C:\Users\austi\Desktop\ctrx\done'


2025-04-07 22:21:01,957 - INFO - Setting parameters for whisperX. For more details, visit: https://github.com/m-bain/whisperX
2025-04-07 22:21:03,973 - INFO - whisper_arch = 'medium'
device = 'cpu' 
compute_type = 'int8'
language = 'en'

2025-04-07 22:21:10,846 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\Users\austi\.cache\torch\whisperx-vad-segmentation.bin`
2025-04-07 22:21:10,882 - INFO - next section loads pyannote auth token

2025-04-07 22:21:13,883 - INFO - 
===================================================================

2025-04-07 22:21:14,187 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\Users\austi\.cache\torch\pyannote\models--pyannote--segmentation\snapshots\c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b\pytorch_model.bin`
2025-04-07 22:21:14,322 - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-07 22:21:14,409 - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-07 22:21:14,784 - INFO - Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-07 22:21:14,866 - INFO - Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-07 22:21:14,955 - INFO - Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-07 22:21:15,018 - INFO - Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-07 22:21:15,086 - INFO - Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder
2025-04-07 22:21:15,290 - INFO - 
===================================================================

2025-04-07 22:21:15,290 - INFO - setup completed.

2025-04-07 22:21:17,300 - INFO - 
we will now begin processing 1 videos

2025-04-07 22:21:18,306 - INFO - 
The time required varies hugely on your computing hardware and selected parameters.

2025-04-07 22:21:18,308 - INFO - Good luck ;/

2025-04-07 22:21:18,309 - INFO - 
===============================

2025-04-07 22:21:18,311 - INFO - Processing video/audio file: C:\Users\austi\Desktop\ctrx\processmesempai\20250404-Murphy This Budget Is Just A Massive Transfer Of Wealth To The Ultra Wealthy.mp4
2025-04-07 22:21:26,898 - INFO - Audio extracted to: imthetrashman\20250404-Murphy This Budget Is Just A Massive Transfer Of Wealth To The Ultra Wealthy_audio.wav
2025-04-07 23:46:00,241 - INFO - Diarization completed.
2025-04-07 23:46:06,310 - ERROR - Error during diarization: get_labels() missing 1 required positional argument: 'segment'
2025-04-07 23:46:56,395 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\Users\austi\.cache\torch\whisperx-vad-segmentation.bin`
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\core\io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:43: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  backend = torchaudio.get_audio_backend()
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0
  from speechbrain.pretrained import (
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:53: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend(backend)
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\tasks\segmentation\mixins.py:37: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.
  from torchaudio.backend.common import AudioMetaData
[nltk_data] Downloading package punkt to
[nltk_data]     C:\Users\austi\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt is already up-to-date!
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\speechbrain\utils\fetching.py:151: UserWarning: Using SYMLINK strategy on Windows for fetching potentially requires elevated privileges and is not recommended. See `LocalStrategy` documentation.
  warnings.warn(
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\speechbrain\utils\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.
  warnings.warn(
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cpu. Bad things might happen unless you revert torch to 1.x.
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cpu. Bad things might happen unless you revert torch to 1.x.
No language specified, language will be first be detected for each audio file (increases inference time).
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cpu. Bad things might happen unless you revert torch to 1.x.
Traceback (most recent call last):
  File "C:\Users\austi\Desktop\ctrx\clipmev2.py", line 219, in <module>
    transcription = transcriber.transcribe(audio_file_path=extracted_audio_path)
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\clipsai\transcribe\transcriber.py", line 107, in transcribe
    transcription = self._model.transcribe(
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\whisperx\asr.py", line 218, in transcribe
    for idx, out in enumerate(self.__call__(data(audio, vad_segments), batch_size=batch_size, num_workers=num_workers)):
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\transformers\pipelines\pt_utils.py", line 124, in __next__
    item = next(self.iterator)
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\transformers\pipelines\pt_utils.py", line 125, in __next__
    processed = self.infer(item, **self.params)
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\transformers\pipelines\base.py", line 1150, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\whisperx\asr.py", line 152, in _forward
    outputs = self.model.generate_segment_batched(model_inputs['inputs'], self.tokenizer, self.options)
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\whisperx\asr.py", line 47, in generate_segment_batched
    encoder_output = self.encode(features)
  File "C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\whisperx\asr.py", line 86, in encode
    return self.model.encode(features, to_cpu=to_cpu)
KeyboardInterrupt
