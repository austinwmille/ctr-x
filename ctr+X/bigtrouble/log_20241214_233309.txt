2024-12-14 23:33:09,375 - INFO - 
==================================================

2024-12-14 23:33:09,377 - INFO - 
Welcome to nips' ctr+X script!

2024-12-14 23:33:11,389 - INFO - 
We are currently using clipmeV2

2024-12-14 23:33:15,795 - INFO - User input: 
2024-12-14 23:33:25,619 - INFO - 
===============================================================================

2024-12-14 23:33:48,738 - INFO - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]
2024-12-14 23:33:48,746 - INFO - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
2024-12-14 23:33:52,798 - INFO - 
===============================================================================

2024-12-14 23:33:52,799 - INFO - 
We're past the first hurdle! Wasn't that fun??

2024-12-14 23:33:54,815 - INFO - Ensuring existence of Danny Devito..

2024-12-14 23:33:55,825 - INFO - 'temp' directory named 'imthetrashman'

2024-12-14 23:33:56,836 - INFO - setting up our folders...

2024-12-14 23:33:57,838 - INFO - folder to put your long videos in: 'C:\Users\austi\Desktop\ctr+X\processmesempai'

2024-12-14 23:33:57,838 - INFO - clips created will be stored in 'C:\Users\austi\Desktop\ctr+X\ctrs'

2024-12-14 23:33:57,839 - INFO - after processing, og video files will move from 'C:\Users\austi\Desktop\ctr+X\processmesempai' to 'C:\Users\austi\Desktop\ctr+X\done'


2024-12-14 23:34:04,245 - INFO - loading some conditions for the AI model (you can play around with the values in the script)

2024-12-14 23:34:06,260 - INFO - whisper_arch = 'base'
device = 'cpu' 
compute_type = 'int8'
language = 'en'

2024-12-14 23:34:07,634 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\Users\austi\.cache\torch\whisperx-vad-segmentation.bin`
2024-12-14 23:34:07,667 - INFO - 
uhhh, just ignore that btw. mine always says that ;)


2024-12-14 23:34:07,667 - INFO - ALRIGHT! we are going to load our pyannote token now

C:\Users\austi\Desktop\ctr+X\cliaenv\lib\site-packages\pyannote\audio\core\io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
C:\Users\austi\Desktop\ctr+X\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:43: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  backend = torchaudio.get_audio_backend()
C:\Users\austi\Desktop\ctr+X\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0
  from speechbrain.pretrained import (
C:\Users\austi\Desktop\ctr+X\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:53: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend(backend)
C:\Users\austi\Desktop\ctr+X\cliaenv\lib\site-packages\pyannote\audio\tasks\segmentation\mixins.py:37: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.
  from torchaudio.backend.common import AudioMetaData
[nltk_data] Downloading package punkt to
[nltk_data]     C:\Users\austi\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cpu. Bad things might happen unless you revert torch to 1.x.
Traceback (most recent call last):
  File "C:\Users\austi\Desktop\ctr+X\clipmev2.py", line 134, in <module>
    logged_input("press enter when ready")
  File "C:\Users\austi\Desktop\ctr+X\clipmev2.py", line 29, in logged_input
    user_input = input()  # Use normal input to capture user response
KeyboardInterrupt
