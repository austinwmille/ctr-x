2025-04-08 13:21:55,448 - INFO - 
==================================================

2025-04-08 13:21:55,448 - INFO - 
nips' brainrot generator

2025-04-08 13:21:55,450 - INFO - 
===============================================================================

2025-04-08 13:22:50,191 - INFO - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]
2025-04-08 13:22:50,191 - INFO - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
2025-04-08 13:22:57,039 - INFO - 
===============================================================================

2025-04-08 13:22:57,039 - INFO - packages loaded

2025-04-08 13:22:59,042 - INFO - setting up folders...

2025-04-08 13:23:00,078 - INFO - 'temp' directory named 'imthetrashman'

2025-04-08 13:23:01,159 - INFO - folder to store un-processed videos: 'C:\Users\austi\Desktop\ctrx\processmesempai'

2025-04-08 13:23:01,159 - INFO - processed clips will be stored in 'C:\Users\austi\Desktop\ctrx\ctrs'

2025-04-08 13:23:01,159 - INFO - after processing, og video files will move from 'C:\Users\austi\Desktop\ctrx\processmesempai' to 'C:\Users\austi\Desktop\ctrx\done'


2025-04-08 13:23:03,169 - INFO - Setting parameters for whisperX. For more details, visit: https://github.com/m-bain/whisperX
2025-04-08 13:23:05,170 - INFO - whisper_arch = 'medium'
device = 'cpu' 
compute_type = 'int8'
language = 'en'

2025-04-08 13:23:12,286 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\Users\austi\.cache\torch\whisperx-vad-segmentation.bin`
2025-04-08 13:23:12,317 - INFO - next section loads pyannote auth token

2025-04-08 13:23:15,327 - INFO - 
===================================================================

2025-04-08 13:23:15,940 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\Users\austi\.cache\torch\pyannote\models--pyannote--segmentation\snapshots\c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b\pytorch_model.bin`
2025-04-08 13:23:16,088 - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:16,240 - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:16,644 - INFO - Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:16,704 - INFO - Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:16,825 - INFO - Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:17,019 - INFO - Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:17,088 - INFO - Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder
2025-04-08 13:23:17,762 - INFO - Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\Users\austi\.cache\torch\pyannote\models--pyannote--segmentation\snapshots\c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b\pytorch_model.bin`
2025-04-08 13:23:17,881 - INFO - Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:17,934 - INFO - Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:18,546 - INFO - Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:18,627 - INFO - Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:18,705 - INFO - Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:18,766 - INFO - Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached
2025-04-08 13:23:18,839 - INFO - Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder
2025-04-08 13:23:19,020 - INFO - 
===================================================================

2025-04-08 13:23:19,020 - INFO - setup completed.

2025-04-08 13:23:21,040 - INFO - 
we will now begin processing 1 videos

2025-04-08 13:23:22,053 - INFO - 
The time required varies hugely on your computing hardware and selected parameters.

2025-04-08 13:23:22,054 - INFO - Good luck ;/

2025-04-08 13:23:22,056 - INFO - 
===============================

2025-04-08 13:23:22,060 - INFO - Processing video/audio file: C:\Users\austi\Desktop\ctrx\processmesempai\20250404-Murphy This Budget Is Just A Massive Transfer Of Wealth To The Ultra Wealthy.mp4
2025-04-08 13:23:30,028 - INFO - Audio extracted to: imthetrashman\20250404-Murphy This Budget Is Just A Massive Transfer Of Wealth To The Ultra Wealthy_audio.wav
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\core\io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend("soundfile")
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:43: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  backend = torchaudio.get_audio_backend()
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0
  from speechbrain.pretrained import (
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\pipelines\speaker_verification.py:53: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
  torchaudio.set_audio_backend(backend)
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\pyannote\audio\tasks\segmentation\mixins.py:37: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.
  from torchaudio.backend.common import AudioMetaData
[nltk_data] Downloading package punkt to
[nltk_data]     C:\Users\austi\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt is already up-to-date!
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\speechbrain\utils\fetching.py:151: UserWarning: Using SYMLINK strategy on Windows for fetching potentially requires elevated privileges and is not recommended. See `LocalStrategy` documentation.
  warnings.warn(
C:\Users\austi\Desktop\ctrx\cliaenv\lib\site-packages\speechbrain\utils\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.
  warnings.warn(
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cpu. Bad things might happen unless you revert torch to 1.x.
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cpu. Bad things might happen unless you revert torch to 1.x.
Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.
Model was trained with torch 1.10.0+cu102, yours is 2.2.0+cpu. Bad things might happen unless you revert torch to 1.x.
Traceback (most recent call last):
  File "C:\Users\austi\Desktop\ctrx\clipmev2.py", line 215, in <module>
    spec.loader.exec_module(local_pyannote)
  File "<frozen importlib._bootstrap_external>", line 846, in exec_module
  File "<frozen importlib._bootstrap_external>", line 983, in get_code
  File "<frozen importlib._bootstrap_external>", line 913, in source_to_code
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "cliaenv\clipsai\clipsai\diarize\pyannote.py", line 232
    """
    ^
IndentationError: expected an indented block
